1. 下载138G的训练数据集                                          # Todo: 在windows上处理，处理好后放到centos上
2. 编写收敛验证，损失记录以及早停策略的代码                          # Todo: 早停参数的设定-Wait
3. classerr的指标以及损失分析，损失变化不大！                       # Todo: 等数据集下载后检查
—————————————————————————————————————————————————————————

# Todo: 2022年4月29日任务
# Todo: 必须完成的：在small_imagenet数据集上训练，并给出统计指标。
1. 参考Distiller项目中的结果统计方法，将其整合到FATE项目中
    (1) 关于data_loggers.collector: 定义了多个指标的收集器,注意context中yield关键字的用法
    (2) 关于utils.py: 定义了压缩指标的基本统计方法,比如sparsity、Apoz的等指标。
    (3) # image_classifier.py中包含使用统计工具的代码
        B. 配置了activation_collectors               # Todo: activation_collectors已经基本跑通
# Todo: 2022年4月30日任务
# Todo: 开始整合   ------整合结果：sparsity整合完毕，过程已进行梳理
——————————————————————————————————————————————————————————
# Todo: 2022年5月1日任务
2. 阅读Distiller项目中的量化源码实现，学习量化策略，将其配置到FATE中   # Todo: Distiller项目，重点
    2.1 读q_utils.py文件和quantizer.py文件   # Todo: 开始看量化代码，专注时间：12：40-14：40  Done！ 2小时+1小时
    2.2 读range_linear.py文件               # Todo: 两个小时专注时间：19：50-21：50        Done!  2小时
    2.3 写周工作汇报                         # Todo: 半小时时间：21：50-22：20             Done!  0.5小时
    # Todo: 要求：不看手机，不打开浏览器。

# Todo: 2022年5月2日任务
3. 5月2日任务
    3.1 继续阅读range_linear.py文件               # Todo: 两个小时专注时间：10：20-12：20 Done! 2小时
    3.2 继续阅读range_linear.py文件               # Todo: 两个小时专注时间：14：30-16：30 Done! 2小时
    3.3 继续阅读range_linear.py文件               # Todo: 两个小时专注时间：19：30-21：30 Done! 2小时
# Todo: just do it!守得云开见月明

4. 5月3日任务
    4.1 继续阅读range_linear.py文件，post_training_quantization部分   # Todo: 基本完成
    4.2 读官方文档，在distiller项目中试着运行量化样例，整合到FATE中        # Todo: 参考distiller代码，在客户端新增量化阶段
        4.2.1 在训练过程中配置统计信息，得到activation_stats            # Todo: 配置完成

    4.3 Todo? 关于模块的替换，matmul等替换函数在哪里？
5. 5月4日任务（周三）
    5.1 将post_train应用到FATE框架中，训练好对模型量化。                             # Todo: Done
    5.2 在valid数据集上对量化的数据集进行验证                                        # Todo: Done
    5.3 将tensor的数据类型转为INT8                                                # Todo: Done
    5.4 将量化后的模型发到服务器端进行聚合                                           # Todo: Done
        5.4.1 对于独立同分布场景，可以认为客户端之间的模型参数接近，因此量化参数接近，可以直接平均
        5.4.2 然而，对于非独立同分布场景，客户端之间的量化参数可能相差很大，因此直接平均效果可能不太好
    5.5 本地解量化，然后开始新一轮的训练                                             # Todo: Done
        5.5.1 反量化的必要性？能否直接在量化点上执行训练
        5.5.2 反量化的方法：quantizer中有保存的量化参数，直接对接收到的量化模型的参数执行反量化，然后将浮点参数更新到优化器上。
——————————————————————————————————————————————————————————
6. 5月5日任务（周四）
    6.1 整理做过的一些工作，整理论文大纲          # Todo: Done
    6.2 配置日志文件，保存中间结果               # Todo: Done
7. 5月6日任务（周五）
    7.1 整理论文大纲
    7.2 解决死循环的问题                       # Todo: Done
8. 5月7日任务（周六）
    8.1 分析剪枝前后模型的总稀疏水平             # Todo: Done，写入文件中
    8.2 量化模型聚合的改进                     # Todo: Done
——————————————————————————————————————————————————————————
9. 5月8日任务（周日）
    9.1 论文"初稿"                                                  # Todo: Done

10. 5月9日任务(周一)
    10.1 验证聚合量化模型的代码                                        # Todo: Done
    10.2 将项目移植到GPU上:对剪枝、量化策略的过程梳理，减少GPU存储占用
        10.2.1 masker                                              # Todo: 推荐GPU，否则需要频繁移动，需要与weight做乘积
        10.2.2 qe-model(GPU)                                       # Todo: 推荐GPU，需要做推理
        10.2.3 record_sparsity(GPU)                                # Todo: 建议CPU
        10.2.4 统计文件的格式化                                       # Todo: Done
    10.4 sensitivity_pruner：只是一个小trick，本质上还是基于数量级别的剪枝 # Todo: 需要进行实验，说明各个层的剪枝敏感性

11. 5月10日任务(周二)
    11.1 task_executor.py 中的profile log         # Todo: Done
12. 5月11日任务(周三)
    12.1 将硬编码的参数写到param配置中                              # Todo: Done
    12.2 对模型的聚合进行更改：增加非量化模型的聚合，便于进行对照实验     # Todo: Done
13. 5月12日任务(周四)
    13.1 稀疏水平升高得太快                 # Todo: 权重的标准差没有及时进行更新，导致几乎所有的权重都被剪掉
    13.2 进行四组实验(剪枝使用预设好的敏感值，每2个epoch进行剪枝，设定start_epoch和end_epoch)   # Todo: Done
        13.2.1 进行非剪枝非量化的实验
        13.2.2 进行剪枝非量化的实验
        13.2.3 进行非剪枝量化的实验
        13.2.4 进行剪枝量化的实验
    13.3 编写记录平均损失的代码                        # Todo: Done
    13.4 已经forward过的qe_model的偏置为int形式       # Todo: Done
14. 5月13日任务(周五)
    14.1 多客户端训练：配置文件到底怎么修改
        14.1.1 看资源申请部分                            # Todo: Done
    14.2 使用5个客户端训练的时候发现在聚合过后的一个epoch中，模型精度随着训练次数的增加而减小
        14.2.1 模型聚合出现问题，没有乘以权重              # Todo: 初步解决
        14.2.2 top1精度上不来，可能是模型聚合频次太块      # Todo: 通过加大epoch参数
    14.3 模型聚合的过程出奇的慢                         # Todo: 在arbiter端配置日志，通过查看日志确定原因
    14.4 对带有batchnorm的模型进行量化                  # Todo: Done
    14.5 模型在一个epoch内的精度呈现下降趋势
        14.5.1 batch调低                             # Todo: batch = 16
        14.5.2 配置学习率衰减                          # Todo: 配置成功
        14.5.3 对dataloader进行shuffle               # Todo Done
        14.5.4 网络结构调简单一些                      # Todo:


15. 5月14日任务(周六)                                 # Todo: 必须完成，不许拖延
    # Todo: 论文部分(First)
    15.3 结构化剪枝的配置                                           # Todo: 最简单的L1RankedStructurePruner  Done
    15.4 quant-aware training                                    # Todo: Here，掌握量化器的结构
#Todo: 论文：对以上部分周六所做工作的文献进行总结

16. 5月15日任务(周日)
    16.1 加入正则化方法,即给损失加入正则项                             # Todo: Done
    16.2 Dynamic Surgery的实现，看Splicing Pruner                  # Todo: Done
    16.4 从distiller项目中继续挖掘比较典型的方法加入到Distiller项目中   # Todo: 不如把现在的工作做好

17. 5月18日任务(周三)
    17.1 解决了量化后模型精度很差的问题，这是因为聚合过程中整型权重溢出造成的                      # Todo: Done
        17.1.1 解决方法：先对整型权重解量化，对解量化的权重进行平均(乘以当前样本数量，除以总样本数量)。
    17.2 解决了统计文件实时写入的问题：file.flush()                                         # Todo: Done
    17.3 模型的稀疏存储？                                                                # Todo: Done

18. 5月21日任务(周六)
    18.1 敏感度分析实验，跑出实验结果（18：50-19：40）                        # Todo:
    18.2 查看实验结果，写组会周报发给罗老师（19：40-20：30）                   # Todo:
    18.3 对已经跑的实验进行基本的整理，写好文档（20：30-21：20）                 # Todo:
    18.4 配置SplicingPruner剪枝方法（21：20-22：10）
    18.5 请教苏函博Latex排版

# Todo: 实验部分(Second)



# Todo: 重点+创新点
11. 参考最新的文献
12. 选几篇已经看过的论文进行复现：比如可恢复的剪枝等等
———————————————————————————————————————————————————————————
关于实验开展的一些想法
一些暂时的设定：
    首先关注对AlexNet模型的压缩
    epoch_every_aggregate = 1，即每个epoch都进行聚合
    先不配置早停，根据图像比较收敛情况
实验一：AlexNet  无Pruning 无Quantize
    1.1 每个epoch记录top1精度、top5精度以及loss
    1.2 每个agg_iter记录平均top1精度、平均top5精度以及loss
实验二：AlexNet  使用SensitivityPruning 无Quantize
    2.1 每个epoch记录top1精度、top5精度以及loss
    2.2 每个agg_iter记录平均top1精度、平均top5精度以及loss
    # Todo: 关于稀疏水平，全连接层的权重一旦被置0后，将不会得到更新，而卷积层不然，因此，只统计全连接层的
    2.3 每次发送模型时全连接层的平均稀疏水平
    2.4 每次接收模型时全连接层的平均稀疏水平
    该实验下的一些问题：
        Q1：本地训练好的稀疏模型，在聚合时会在服务器端进行模型平均，平均后的模型可能是比较稠密的-->只减小了发送模型的通信压力
        Q2：稀疏水平降低一定代表模型所占存储变小了吗？# Todo: 如果对发送的参数列表进行所占存储大小的定量？
实验三：AlexNet  使用SensitivityPruning 使用PostTrainQuantize
    3.1 每个epoch记录量化前模型的top1精度、top5精度以及loss
    3.2 每个epoch记录量化后模型的top1精度、top5精度以及loss # Todo: 根据3.1和3.2数据的对比判断量化后模型的精度如何
    3.3 每个agg_iter记录量化后模型的平均top1精度、top5精度以及loss
    3.4 每次聚合时发送的参数列表的大小、接收的参数列表的大小   # Todo: 从weight由float32量化为int8，参数列表应该会大幅度减小


毕设完成后的一些查缺补楼
1. 包的循环导入问题