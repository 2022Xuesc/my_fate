epoch,mAP,train_loss
0,83.4000015258789,6.361142492882763
1,82.01667022705078,6.072818089625952
2,89.81666564941406,5.874315158018713
3,90.48332977294922,5.392020312639717
4,91.48333740234375,4.617116134355445
5,91.86666870117188,4.080727220161769
6,92.73333740234375,3.49133553488265
7,97.0666732788086,2.8828376975420555
8,91.86666870117188,4.116279640471364
9,94.73333740234375,2.961278341525223
10,96.20000457763672,2.360850218999135
11,95.06665802001953,1.7608565579357183
12,90.73333740234375,4.048195453493927
13,93.73333740234375,3.2155168835940584
14,98.33332824707031,2.300008184440734
15,92.26667022705078,2.0230259939808466
16,87.26666259765625,4.353289665555053
17,97.0666732788086,3.314229224068254
18,97.0666732788086,2.649614606255579
19,97.19999694824219,2.1319554530139726
20,91.86666870117188,4.601957552035082
21,93.60000610351562,3.9303983366674644
22,93.73332977294922,3.195526399081381
23,96.20000457763672,2.533275396539789
24,93.5999984741211,4.729670964869849
25,88.93333435058594,3.625370815415613
26,94.39999389648438,3.0985902985755325
27,97.53333282470703,2.5789005285136284
28,89.9333267211914,4.259752249147129
29,96.20000457763672,3.6405889364387725
30,97.53333282470703,3.2742254363614793
31,96.20000457763672,2.928893082798781
32,89.26666259765625,5.5337432278287375
33,92.06666564941406,5.188753682555694
34,94.39999389648438,4.712159014191034
35,96.06666564941406,4.639161691566655
36,95.4000015258789,5.720518645012183
37,96.86666870117188,5.882561118261101
38,91.06666564941406,5.617318074538893
39,96.06666564941406,5.438955079979523
