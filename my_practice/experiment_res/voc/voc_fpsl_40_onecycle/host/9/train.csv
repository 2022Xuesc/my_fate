epoch,mAP,train_loss
0,90.7833251953125,3.852305014928182
1,97.53333282470703,3.6472578048706055
2,91.45000457763672,3.6375884215037027
3,97.53333282470703,3.232799688975016
4,88.26667022705078,4.274923960367839
5,94.86666870117188,3.5865297317504883
6,91.26667022705078,3.0452568531036377
7,93.73332977294922,2.440878470738729
8,95.19999694824219,3.2661460240681968
9,92.06666564941406,2.4462729692459106
10,90.26667022705078,1.6653493642807007
11,98.53333282470703,1.1102669835090637
12,94.86666870117188,3.970721165339152
13,94.06666564941406,2.9398595492045083
14,94.53333282470703,2.0624461571375527
15,91.73332977294922,1.612745722134908
16,94.06666564941406,4.056335926055908
17,95.86666870117188,2.8030638694763184
18,94.06666564941406,2.0289756059646606
19,100.0,1.430368185043335
20,96.20000457763672,3.983131488164266
21,94.73333740234375,2.9649462699890137
22,91.93333435058594,2.5428638458251953
23,99.33333587646484,1.4580637613932292
24,93.06666564941406,4.62237564722697
25,93.73332977294922,3.194830576578776
26,91.26667022705078,2.8044180870056152
27,92.48334503173828,2.497840325037638
28,93.73333740234375,4.547823270161946
29,94.86666870117188,3.6762758096059165
30,91.73332977294922,2.992607752482096
31,98.33334350585938,2.692516883214315
32,92.26667022705078,5.194711049397786
33,94.39999389648438,4.826850573221843
34,92.26667022705078,4.37246831258138
35,95.53333282470703,4.377508481343587
36,92.06666564941406,6.775522549947103
37,88.5999984741211,6.007405122121175
38,93.5999984741211,5.964842478434245
39,93.5999984741211,6.033200263977051
