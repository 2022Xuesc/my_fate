epoch,mAP,train_loss
0,93.5999984741211,5.79571628669191
1,96.86666870117188,3.9559350097835275
2,98.53333282470703,2.801499461680854
3,100.0,2.015206861619865
4,93.73333740234375,10.455233862535662
5,93.53334045410156,7.986450404298129
6,95.19999694824219,6.123127370587392
7,93.73333740234375,4.705221547862132
8,88.73332977294922,12.302695633749446
9,93.73332977294922,10.44945700710738
10,96.06666564941406,8.171745679537244
11,96.86666870117188,5.454891936638732
12,93.15000915527344,12.229136285182456
13,95.53333282470703,10.335269398302785
14,93.73332977294922,7.802532533893882
15,99.33333587646484,6.180409408617779
16,89.93333435058594,15.317072656312487
17,96.20000457763672,12.417656796449377
18,92.73333740234375,10.719927962402362
19,97.86666870117188,8.28522514820442
20,97.53333282470703,15.552786864786407
21,92.53334045410156,15.240238629189719
22,93.53334045410156,12.022638492183125
23,99.33333587646484,9.451366744934184
24,92.06666564941406,18.179998242496865
25,96.20000457763672,14.433652845395768
26,93.06666564941406,12.7949875695705
27,94.39999389648438,11.397759899125893
28,94.61666107177734,17.95640655906488
29,97.86666870117188,16.146215065581806
30,93.8166732788086,15.910111547179268
31,96.86666870117188,11.506960717442666
32,96.86666870117188,19.625509009493154
33,93.73332977294922,18.48690984316359
34,96.20000457763672,16.12035578535382
35,94.53333282470703,13.891897821943413
36,92.59999084472656,21.48028104499695
37,95.06665802001953,19.615351160254974
38,97.86666870117188,17.882138493079026
39,96.86666870117188,16.38943384336567
