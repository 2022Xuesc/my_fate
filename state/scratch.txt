1. 已进行实验
    IID：
        Resnet基准实验v1 ： 202305140624042428120   Complete         Todo: 初步参考，正则化参数为0.00025，与选择模型不符
        Resnet基准实验v2 ：  Todo: 有机会重跑，正则化参数为0.000025，与选择模型不符
        GCN基准实验      ： 202305290247327779340   Complete
        SST基准实验      ： 202306031322539863800   Complete
        SRN基准实验      ： 202306060542213710800   Complete
        LSTM基准实验     ：  Todo：熟悉流程+编写配置文件
    NON-IID(异步跑，聚合权重的设置)：
        FedAvg聚合方式下的Resnet: 202306020309478663470              Todo: 有时间需要重跑一下，过于离谱
        #Todo: 有机会重跑，有点问题
        FLAG异步复现Resnet  ：  202306011216232843380                   Todo: 数量较小的客户端只有44左右的mAP
        FLAG同步复现Resnet  ：  202306230844513394680
        FPSL同步复现ResNet  ：  202306241255064865930
        FLAG复现GCN     ：
        FLAG复现LSTM    ：

    NON-IID(同步跑，带有数据压缩)：
        使用模型       深浅层传输         传输比例                       是否保存本地训练进度          任务ID
        FPSL           全层         固定lambda（l = 1）                    否                  202307031207046456290
        FPSL           全层         固定lambda（l = 1）                    是                  202307031341257538810
        FPSL          conv和bn截断     不压缩                              否                  202307060942416167420
        FPSL          conv和bn保留     不压缩                              否                  202307090633491193810
 --------------------------------------------7月10日---------------------------------------------------------------------
        FPSL           全层         每层不同传输率(LAMP论文复现)              否                  202307111347573628130
        FPSL      最后一个fc作为深层     不压缩                              否                  202307130703172825950
        FPSL           全层         DepGraph剪去耦合的组参数                 否                  202307210406299895830
        FPSL           全层       DepGraph剪去person标签对应的通道数          否                 202307231222374674240
 --------------------------------------------8月28日---------------------------------------------------------------------
        FPSL         71划分浅层   固定lambda(l = 1)+topk                否                 202308261030023953730
        FPSL         71划分浅层     固定lambda(l = 1)+dep                  否                 202308261138265113260
        FPSL         71划分浅层      不压缩                                否

 Todo: 加上BN层的修正  (模型性能有提升)
 --------------------------------------------8月29日---------------------------------------------------------------------
     FPSL + BN         全                     全                          否                202308291235590686010
     FPSL + BN        71划分浅层             不压缩                         否                202309020759060689870



Todo: 标签相关性相关

MS-COCO（中途报错了）
Naive-Interactive: 202310071404247104770
修正的Interactive: 202310080325352859490

VOC2007
FPSL: 202310111620484015140
Interactive: 202310111625160112650

Todo: VOC2007_Expanded（AdamW）
FPSL: 202310120353361894560
Interactive: 202310120424303031750

Todo: (APs + Loss分析)
FPSL
    iter = 10
        OneCycle: 202310141058527568340  Todo: Done
    iter = 50
        OneCycle: 202310141445536543540  Todo: Done
        Plateau:  202310150238458578470  Todo: Done
        Plateau + wd(1e-3):  202310160148116520430 Todo: Done
        resnet50+scale224:   202310170710395507420

Interactive:
    iter = 10: 202310141100215339370 Todo: 分析一下相关性变化
    iter = 50:
Fixed_Interactive:
    iter = 10: 202310151329296348000 Todo: Done，感觉跑得不够
    iter = 50: 202310161514455808460 Todo: Done，精度一般
Handle interactive Todo: (代码改正)

编写结果脚本
prime: 202310120353361894560
interactive: 202310130900418558910

Todo: 过拟合的实验分析
1. weight_decay设置过小
    1e-3: 202310160148116520430
2. 模型容量过大
    resnet50+(256-224)：202310170710395507420
3. 非预训练模型:



Todo: 新阶段
FPSL: 202310231310172307300
GCN: 202310240400134935640
GCN-large: 202310250402450650030

P-GCN(有问题)
    FC层直接聚合:   202310300846169579740
    FC层分标签聚合: 202310300850096375660


P-GCN
    FC层直接聚合: 202311010602305386810
    FC层分标签聚合: 202311010604035876740

SAL-GL:
    场景：202311111417148328210
    

Transformer
    
























Todo: 同步异步实验切换要修改的地方:
1. sync参数
2. 聚合器的选择
3. 损失的发送和平均: 异步联邦学习无损失平均可言   #Todo: 好像也可以进行加权

Todo: 学到的教训
1. 服务器中部署训练时不要频繁输出日志，对模型训练的速度影响很大
2. sync参数的修改位置：fate/python/fate_arch/federation/transfer_variable.py
3. Todo: ndarray不能直接=赋值，这样得到的是引用，使用np.copy()进行值拷贝
4. np.linalg.norm(ord=2)和torch.norm(p=2)的区别

Todo: 元学习部分的相关考虑
1. support set和query set的划分比例？
2. 批次内划分还是批次外划分？
3. 是否在query set中更新phi？


Todo: 元学习疑难杂症
划分位置    query set中更新phi   support：query      训练结果
批次外             是                 1：1            失败
批次外             是                 1：9

2023年7月23日任务
1. 遍历多张图像，找出人在每一层对应的显著通道，记录下来
2. 启动实验，训练时候剪去对应的组，统计稀疏率
3. 比较性能

# Cam + DepGraph结合实验难点
1. 对于较深的层，非0映射的通道数很少，比如最后一个卷积层非0映射占比为：3 / 2048   Todo: 是否需要根据其他指标计算通道重要性？
2. 4个下采样层没有relu，其余conv都有relu
3. 关于残差块参数分组的合并

# Todo: 最新的任务
0. 先跑一下只进行split的实验                                   Todo: Ongoing
1. 重跑一下FPSL的实验，加上BN层统计数据的聚合                     Todo: Done
2. 验证输出是否有多样性                                        Todo: 确实具有多样性,说明了running_mean和running_var的重要性
3. 统计各个标签激活的通道的特征，关注重要标签和不重要标签的交集大小


Todo: 对通道的分析
1. 每一层每个标签的通道向量是否具有相关性
2. 不同重要因子下，重要标签和不重要标签的交并比IOU

Todo: 4.
(1) 从相关性角度出发，制定剪枝策略（强化连接，可达性分析等等）
(2) 选择重要标签时，使用max还是sum


9月17日
FPSL + 交互式相关性
1. 客户端统计各自的数据集，初始化标签相关性                                                 Todo: Here
2. 定义标签相关性损失，优化标签相关性
3. 使用初始化的CNN参数，执行前向传播，计算出每个图像的特征输出和预测概率
4. 执行正交匹配追踪算法OMP，计算图像相似性（语义相似性和特征相似性）
5. 计算好之后，进行反向传播，优化CNN参数，模型参与聚合。
6. 标签相关性是否也需要参与聚合？分析利弊（1. 前期，不鲁棒；2. 后期，基本正确后再进行聚合）


Todo: 结果比较
https://arxiv.org/pdf/1406.5726.pdf
https://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_CNN-RNN_A_Unified_CVPR_2016_paper.pdf

Todo: 聚合关于每个类别的ap值，对于VOC数据集

Todo: 关于相关性阈值的设定

Todo: relation_optimizer的学习率设置

Todo: 将重加权部分其改成自适应的公式?

Todo: 这里考虑错了，对相关性预测方法进行重计算
1. 如果A标签的出现概率较低，则不能使用P(B|A)进行计算。 Todo: 可以使用P(B|A')进行计算，且概率越低，预测置信度越高
2. 如果A标签的出现概率较高，则可以使用P(B|A)矩阵
    (1) P(B|A)较小，则A对B标签的预测起抑制作用，P(A)越高，P(B)越低，通过1 - P(A) * (1 - P(B|A))计算
    (2) P(B|A)较大，则A对B标签的预测起促进作用，P(A)越高，P(B)越高，通过P(A) * P(B)进行计算